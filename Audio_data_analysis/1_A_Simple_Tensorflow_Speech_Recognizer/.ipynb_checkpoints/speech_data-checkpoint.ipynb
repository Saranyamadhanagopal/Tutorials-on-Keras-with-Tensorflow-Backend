{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utilities for downloading and providing data from openslr.org, libriSpeech, Pannous, Gutenberg, WMT, tokenizing, vocabularies.\"\"\"\n",
    "# TODO! see https://github.com/pannous/caffe-speech-recognition for some data sources\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import wave\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "import skimage.io  # scikit-image\n",
    "import librosa\n",
    "import matplotlib\n",
    "# try:\n",
    "#\n",
    "# except:\n",
    "#   print(\"pip install librosa ; if you want mfcc_batch_generator\")\n",
    "\n",
    "# import extensions as xx\n",
    "from random import shuffle\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "\n",
    "# TRAIN_INDEX='train_words_index.txt'\n",
    "# TEST_INDEX='test_words_index.txt'\n",
    "SOURCE_URL = 'http://pannous.net/files/' #spoken_numbers.tar'\n",
    "DATA_DIR = 'data/'\n",
    "pcm_path = \"data/spoken_numbers_pcm/\" # 8 bit\n",
    "wav_path = \"data/spoken_numbers_wav/\" # 16 bit s16le\n",
    "path = pcm_path\n",
    "CHUNK = 4096\n",
    "test_fraction=0.1 # 10% of data for test / verification\n",
    "\n",
    "# http://pannous.net/files/spoken_numbers_pcm.tar\n",
    "class Source:  # labels\n",
    "  DIGIT_WAVES = 'spoken_numbers_pcm.tar'\n",
    "  DIGIT_SPECTROS = 'spoken_numbers_spectros_64x64.tar'  # 64x64  baby data set, works astonishingly well\n",
    "  NUMBER_WAVES = 'spoken_numbers_wav.tar'\n",
    "  NUMBER_IMAGES = 'spoken_numbers.tar'  # width=256 height=256\n",
    "  WORD_SPECTROS = 'https://dl.dropboxusercontent.com/u/23615316/spoken_words.tar'  # width,height=512# todo: sliding window!\n",
    "  TEST_INDEX = 'test_index.txt'\n",
    "  TRAIN_INDEX = 'train_index.txt'\n",
    "\n",
    "from enum import Enum\n",
    "class Target(Enum):  # labels\n",
    "  digits=1\n",
    "  speaker=2\n",
    "  words_per_minute=3\n",
    "  word_phonemes=4\n",
    "  word=5#characters=5\n",
    "  sentence=6\n",
    "  sentiment=7\n",
    "  first_letter=8\n",
    "\n",
    "\n",
    "\n",
    "def progresshook(blocknum, blocksize, totalsize):\n",
    "    readsofar = blocknum * blocksize\n",
    "    if totalsize > 0:\n",
    "        percent = readsofar * 1e2 / totalsize\n",
    "        s = \"\\r%5.1f%% %*d / %d\" % (\n",
    "            percent, len(str(totalsize)), readsofar, totalsize)\n",
    "        sys.stderr.write(s)\n",
    "        if readsofar >= totalsize: # near the end\n",
    "            sys.stderr.write(\"\\n\")\n",
    "    else: # total size is unknown\n",
    "        sys.stderr.write(\"read %d\\n\" % (readsofar,))\n",
    "\n",
    "def maybe_download(file, work_directory):\n",
    "  \"\"\"Download the data from Pannous's website, unless it's already here.\"\"\"\n",
    "  print(\"Looking for data %s in %s\"%(file,work_directory))\n",
    "  if not os.path.exists(work_directory):\n",
    "    os.mkdir(work_directory)\n",
    "  filepath = os.path.join(work_directory, re.sub('.*\\/','',file))\n",
    "  if not os.path.exists(filepath):\n",
    "    if not file.startswith(\"http\"): url_filename = SOURCE_URL + file\n",
    "    else: url_filename=file\n",
    "    print('Downloading from %s to %s' % (url_filename, filepath))\n",
    "    filepath, _ = urllib.request.urlretrieve(url_filename, filepath,progresshook)\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', file, statinfo.st_size, 'bytes.')\n",
    "    # os.system('ln -s '+work_directory)\n",
    "  if os.path.exists(filepath):\n",
    "    print('Extracting %s to %s' % ( filepath, work_directory))\n",
    "    os.system('tar xf %s -C %s' % ( filepath, work_directory))\n",
    "    print('Data ready!')\n",
    "  return filepath.replace(\".tar\",\"\")\n",
    "\n",
    "def spectro_batch(batch_size=10):\n",
    "  return spectro_batch_generator(batch_size)\n",
    "\n",
    "def speaker(file):  # vom Dateinamen\n",
    "  # if not \"_\" in file:\n",
    "  #   return \"Unknown\"\n",
    "  return file.split(\"_\")[1]\n",
    "\n",
    "def get_speakers(path=pcm_path):\n",
    "  files = os.listdir(path)\n",
    "  def nobad(file):\n",
    "    return \"_\" in file and not \".\" in file.split(\"_\")[1]\n",
    "  speakers=list(set(map(speaker,filter(nobad,files))))\n",
    "  print(len(speakers),\" speakers: \",speakers)\n",
    "  return speakers\n",
    "\n",
    "def load_wav_file(name):\n",
    "  f = wave.open(name, \"rb\")\n",
    "  # print(\"loading %s\"%name)\n",
    "  chunk = []\n",
    "  data0 = f.readframes(CHUNK)\n",
    "  while data0:  # f.getnframes()\n",
    "    # data=numpy.fromstring(data0, dtype='float32')\n",
    "    # data = numpy.fromstring(data0, dtype='uint16')\n",
    "    data = numpy.fromstring(data0, dtype='uint8')\n",
    "    data = (data + 128) / 255.  # 0-1 for Better convergence\n",
    "    # chunks.append(data)\n",
    "    chunk.extend(data)\n",
    "    data0 = f.readframes(CHUNK)\n",
    "  # finally trim:\n",
    "  chunk = chunk[0:CHUNK * 2]  # should be enough for now -> cut\n",
    "  chunk.extend(numpy.zeros(CHUNK * 2 - len(chunk)))  # fill with padding 0's\n",
    "  # print(\"%s loaded\"%name)\n",
    "  return chunk\n",
    "\n",
    "\n",
    "def spectro_batch_generator(batch_size=10,width=64,source_data=Source.DIGIT_SPECTROS,target=Target.digits):\n",
    "  # maybe_download(Source.NUMBER_IMAGES , DATA_DIR)\n",
    "  # maybe_download(Source.SPOKEN_WORDS, DATA_DIR)\n",
    "  path=maybe_download(source_data, DATA_DIR)\n",
    "  path=path.replace(\"_spectros\",\"\")# HACK! remove!\n",
    "  height = width\n",
    "  batch = []\n",
    "  labels = []\n",
    "  speakers=get_speakers(path)\n",
    "  if target==Target.digits: num_classes=10\n",
    "  if target==Target.first_letter: num_classes=32\n",
    "  files = os.listdir(path)\n",
    "  # shuffle(files) # todo : split test_fraction batch here!\n",
    "  # files=files[0:int(len(files)*(1-test_fraction))]\n",
    "  print(\"Got %d source data files from %s\"%(len(files),path))\n",
    "  while True:\n",
    "    # print(\"shuffling source data files\")\n",
    "    shuffle(files)\n",
    "    for image_name in files:\n",
    "      if not \"_\" in image_name: continue # bad !?!\n",
    "      image = skimage.io.imread(path + \"/\" + image_name).astype(numpy.float32)\n",
    "      # image.resize(width,height) # lets see ...\n",
    "      data = image / 255.  # 0-1 for Better convergence\n",
    "      data = data.reshape([width * height])  # tensorflow matmul needs flattened matrices wtf\n",
    "      batch.append(list(data))\n",
    "      # classe=(ord(image_name[0]) - 48)  # -> 0=0 .. A:65-48 ... 74 for 'z'\n",
    "      classe = (ord(image_name[0]) - 48) % 32# -> 0=0  17 for A, 10 for z ;)\n",
    "      labels.append(dense_to_one_hot(classe,num_classes))\n",
    "      if len(batch) >= batch_size:\n",
    "        yield batch, labels\n",
    "        batch = []  # Reset for next batch\n",
    "        labels = []\n",
    "\n",
    "def mfcc_batch_generator(batch_size=10, source=Source.DIGIT_WAVES, target=Target.digits):\n",
    "  maybe_download(source, DATA_DIR)\n",
    "  if target == Target.speaker: speakers = get_speakers()\n",
    "  batch_features = []\n",
    "  labels = []\n",
    "  files = os.listdir(path)\n",
    "  while True:\n",
    "    print(\"loaded batch of %d files\" % len(files))\n",
    "    shuffle(files)\n",
    "    for wav in files:\n",
    "      if not wav.endswith(\".wav\"): continue\n",
    "      wave, sr = librosa.load(path+wav, mono=True)\n",
    "      if target==Target.speaker: label=one_hot_from_item(speaker(wav), speakers)\n",
    "      elif target==Target.digits:  label=dense_to_one_hot(int(wav[0]),10)\n",
    "      elif target==Target.first_letter:  label=dense_to_one_hot((ord(wav[0]) - 48) % 32,32)\n",
    "      else: raise Exception(\"todo : labels for Target!\")\n",
    "      labels.append(label)\n",
    "      mfcc = librosa.feature.mfcc(wave, sr)\n",
    "      # print(np.array(mfcc).shape)\n",
    "      mfcc=np.pad(mfcc,((0,0),(0,80-len(mfcc[0]))), mode='constant', constant_values=0)\n",
    "      batch_features.append(np.array(mfcc))\n",
    "      if len(batch_features) >= batch_size:\n",
    "        # print(np.array(batch_features).shape)\n",
    "        # yield np.array(batch_features), labels\n",
    "        yield batch_features, labels  # basic_rnn_seq2seq inputs must be a sequence\n",
    "        batch_features = []  # Reset for next batch\n",
    "        labels = []\n",
    "\n",
    "\n",
    "# If you set dynamic_pad=True when calling tf.train.batch the returned batch will be automatically padded with 0s. Handy! A lower-level option is to use tf.PaddingFIFOQueue.\n",
    "# only apply to a subset of all images at one time\n",
    "def wave_batch_generator(batch_size=10,source=Source.DIGIT_WAVES,target=Target.digits): #speaker\n",
    "  maybe_download(source, DATA_DIR)\n",
    "  if target == Target.speaker: speakers=get_speakers()\n",
    "  batch_waves = []\n",
    "  labels = []\n",
    "  # input_width=CHUNK*6 # wow, big!!\n",
    "  files = os.listdir(path)\n",
    "  while True:\n",
    "    shuffle(files)\n",
    "    print(\"loaded batch of %d files\" % len(files))\n",
    "    for wav in files:\n",
    "      if not wav.endswith(\".wav\"):continue\n",
    "      if target==Target.digits: labels.append(dense_to_one_hot(int(wav[0])))\n",
    "      elif target==Target.speaker: labels.append(one_hot_from_item(speaker(wav), speakers))\n",
    "      elif target==Target.first_letter:  label=dense_to_one_hot((ord(wav[0]) - 48) % 32,32)\n",
    "      else: raise Exception(\"todo : Target.word label!\")\n",
    "      chunk = load_wav_file(path+wav)\n",
    "      batch_waves.append(chunk)\n",
    "      # batch_waves.append(chunks[input_width])\n",
    "      if len(batch_waves) >= batch_size:\n",
    "        yield batch_waves, labels\n",
    "        batch_waves = []  # Reset for next batch\n",
    "        labels = []\n",
    "\n",
    "class DataSet(object):\n",
    "\n",
    "  def __init__(self, images, labels, fake_data=False, one_hot=False, load=False):\n",
    "    \"\"\"Construct a DataSet. one_hot arg is used only if fake_data is true.\"\"\"\n",
    "    if fake_data:\n",
    "      self._num_examples = 10000\n",
    "      self.one_hot = one_hot\n",
    "    else:\n",
    "      num = len(images)\n",
    "      assert num == len(labels), ('images.shape: %s labels.shape: %s' % (images.shape, labels.shape))\n",
    "      print(\"len(images) %d\" % num)\n",
    "      self._num_examples = num\n",
    "    self.cache={}\n",
    "    self._image_names = numpy.array(images)\n",
    "    self._labels = labels\n",
    "    self._epochs_completed = 0\n",
    "    self._index_in_epoch = 0\n",
    "    self._images=[]\n",
    "    if load: # Otherwise loaded on demand\n",
    "      self._images=self.load(self._image_names)\n",
    "\n",
    "  @property\n",
    "  def images(self):\n",
    "    return self._images\n",
    "\n",
    "  @property\n",
    "  def image_names(self):\n",
    "    return self._image_names\n",
    "\n",
    "  @property\n",
    "  def labels(self):\n",
    "    return self._labels\n",
    "\n",
    "  @property\n",
    "  def num_examples(self):\n",
    "    return self._num_examples\n",
    "\n",
    "  @property\n",
    "  def epochs_completed(self):\n",
    "    return self._epochs_completed\n",
    "\n",
    "  # only apply to a subset of all images at one time\n",
    "  def load(self,image_names):\n",
    "    print(\"loading %d images\"%len(image_names))\n",
    "    return list(map(self.load_image,image_names)) # python3 map object WTF\n",
    "\n",
    "  def load_image(self,image_name):\n",
    "    if image_name in self.cache:\n",
    "        return self.cache[image_name]\n",
    "    else:\n",
    "      image = skimage.io.imread(DATA_DIR+ image_name).astype(numpy.float32)\n",
    "      # images = numpy.multiply(images, 1.0 / 255.0)\n",
    "      self.cache[image_name]=image\n",
    "      return image\n",
    "\n",
    "\n",
    "  def next_batch(self, batch_size, fake_data=False):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    if fake_data:\n",
    "      fake_image = [1] * width * height\n",
    "      if self.one_hot:\n",
    "        fake_label = [1] + [0] * 9\n",
    "      else:\n",
    "        fake_label = 0\n",
    "      return [fake_image for _ in xrange(batch_size)], [\n",
    "          fake_label for _ in xrange(batch_size)]\n",
    "    start = self._index_in_epoch\n",
    "    self._index_in_epoch += batch_size\n",
    "    if self._index_in_epoch > self._num_examples:\n",
    "      # Finished epoch\n",
    "      self._epochs_completed += 1\n",
    "      # Shuffle the data\n",
    "      perm = numpy.arange(self._num_examples)\n",
    "      numpy.random.shuffle(perm)\n",
    "      # self._images = self._images[perm]\n",
    "      self._image_names = self._image_names[perm]\n",
    "      self._labels = self._labels[perm]\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      self._index_in_epoch = batch_size\n",
    "      assert batch_size <= self._num_examples\n",
    "    end = self._index_in_epoch\n",
    "    return self.load(self._image_names[start:end]), self._labels[start:end]\n",
    "\n",
    "\n",
    "# multi-label\n",
    "def dense_to_some_hot(labels_dense, num_classes=140):\n",
    "  \"\"\"Convert class labels from int vectors to many-hot vectors!\"\"\"\n",
    "  raise \"TODO dense_to_some_hot\"\n",
    "\n",
    "\n",
    "def one_hot_to_item(hot, items):\n",
    "  i=np.argmax(hot)\n",
    "  item=items[i]\n",
    "  return item\n",
    "\n",
    "def one_hot_from_item(item, items):\n",
    "  # items=set(items) # assure uniqueness\n",
    "  x=[0]*len(items)# numpy.zeros(len(items))\n",
    "  i=items.index(item)\n",
    "  x[i]=1\n",
    "  return x\n",
    "\n",
    "def dense_to_one_hot(batch, batch_size, num_labels):\n",
    "  sparse_labels = tf.reshape(batch, [batch_size, 1])\n",
    "  indices = tf.reshape(tf.range(0, batch_size, 1), [batch_size, 1])\n",
    "  concatenated = tf.concat(1, [indices, sparse_labels])\n",
    "  concat = tf.concat(0, [[batch_size], [num_labels]])\n",
    "  output_shape = tf.reshape(concat, [2])\n",
    "  sparse_to_dense = tf.sparse_to_dense(concatenated, output_shape, 1.0, 0.0)\n",
    "  return tf.reshape(sparse_to_dense, [batch_size, num_labels])\n",
    "\n",
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "  \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "  return numpy.eye(num_classes)[labels_dense]\n",
    "\n",
    "def extract_labels(names_file,train, one_hot):\n",
    "  labels=[]\n",
    "  for line in open(names_file).readlines():\n",
    "    image_file,image_label = line.split(\"\\t\")\n",
    "    labels.append(image_label)\n",
    "  if one_hot:\n",
    "      return dense_to_one_hot(labels)\n",
    "  return labels\n",
    "\n",
    "def extract_images(names_file,train):\n",
    "  image_files=[]\n",
    "  for line in open(names_file).readlines():\n",
    "    image_file,image_label = line.split(\"\\t\")\n",
    "    image_files.append(image_file)\n",
    "  return image_files\n",
    "\n",
    "\n",
    "def read_data_sets(train_dir,source_data=Source.NUMBER_IMAGES, fake_data=False, one_hot=True):\n",
    "  class DataSets(object):\n",
    "    pass\n",
    "  data_sets = DataSets()\n",
    "  if fake_data:\n",
    "    data_sets.train = DataSet([], [], fake_data=True, one_hot=one_hot)\n",
    "    data_sets.validation = DataSet([], [], fake_data=True, one_hot=one_hot)\n",
    "    data_sets.test = DataSet([], [], fake_data=True, one_hot=one_hot)\n",
    "    return data_sets\n",
    "  VALIDATION_SIZE = 2000\n",
    "  local_file = maybe_download(source_data, train_dir)\n",
    "  train_images = extract_images(TRAIN_INDEX,train=True)\n",
    "  train_labels = extract_labels(TRAIN_INDEX,train=True, one_hot=one_hot)\n",
    "  test_images = extract_images(TEST_INDEX,train=False)\n",
    "  test_labels = extract_labels(TEST_INDEX,train=False, one_hot=one_hot)\n",
    "  # train_images = train_images[:VALIDATION_SIZE]\n",
    "  # train_labels = train_labels[:VALIDATION_SIZE:]\n",
    "  # test_images = test_images[VALIDATION_SIZE:]\n",
    "  # test_labels = test_labels[VALIDATION_SIZE:]\n",
    "  data_sets.train = DataSet(train_images, train_labels , load=False)\n",
    "  data_sets.test = DataSet(test_images, test_labels, load=True)\n",
    "  # data_sets.validation = DataSet(validation_images, validation_labels, load=True)\n",
    "  return data_sets\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  print(\"downloading speech datasets\")\n",
    "  maybe_download( Source.DIGIT_SPECTROS)\n",
    "  maybe_download( Source.DIGIT_WAVES)\n",
    "  maybe_download( Source.NUMBER_IMAGES)\n",
    "  maybe_download( Source.NUMBER_WAVES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
